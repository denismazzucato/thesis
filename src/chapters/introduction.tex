\pagelayout{wide} % No margins
\addpart{Introduction}
\labpart{introduction}
\pagelayout{margin} % Restore margins
\setchapterpreamble[u]{\margintoc}


\chapter{Introduction}
\labch{introduction}


Recent advances and evolution in software development have led to increasingly complex software systems.
The reliability of these systems is based on their correctness.
Any failure or vulnerability in software poses significant risks, potentially threatening human safety or causing financial losses.
As software grows in complexity, the likelihood of bugs also increases.
The effort and cost of fixing these bugs escalate with late detection, as illustrated in \reftab{effort-to-fix} \sidecite{White2017}, which shows the relative costs of fixing bugs at different development stages.

\begin{margintable}
  \caption{Cost of fixing bugs at different development stages \cite{White2017}.}
  \labtab{effort-to-fix}
  \centering
  \resizebox{\textwidth}{!}{
  \begin{tabular}{c c}
    \toprule
    \textsc{Bug Found at Stage} & \textsc{Cost to Fix} \\
    \midrule
    Requirements & 1x (definition) \\
    Architecture & 3x \\
    Design & 5-10x \\
    System Test & 10x \\
    Production & 10-100x \\
    \bottomrule
  \end{tabular}
  }
\end{margintable}


In today's world, software rules safety-critical systems such as nuclear power plants \sidecite{Krasner2021},
car engines \sidecite{Finch2009},
airplane control systems
\sidecite{Briere1993},
and medical devices \sidecite{Leveson1993}.
For these systems, detecting and addressing bugs before deployment is mandatory to ensure safety.

Beyond traditional software, the rise of machine learning software has introduced new challenges.
Machine learning is increasingly impacting society by assisting or even automating decision-making in fields such as social welfare \sidecite{Larson2016}, criminal justice \sidecite{Buolamwini2018}, and healthcare \sidecite{Obermeyer2019}.
However, recent cases have shown that such software can reproduce or even reinforce biases present in the training data \cite{Buolamwini2018,Kay2015,Larson2016,Obermeyer2019}\phantomcite{Kay2015}.
In response to the rise of machine learning software based software, and thus the potential risks associated with it, the European Commission proposed the Artificial Intelligence Act~\sidecite{Commission2021}: a first legal framework on machine learning software, imposing strict requirements to minimize the risk of discriminatory outcomes.
Detecting bugs and bias in machine learning software is crucial to ensure that the software behaves as intended and does not harm users.


Even more recently, the last advancements in artificial intelligence have led to the rise of large language models (LLMs) capable of generating software from natural language specifications.
Agents like OpenAI's ChatGPT\sidenote{\rurl{chatgpt.com}} and Google's Gemini\sidenote{\rurl{gemini.google.com}} are gaining widespread use.
Specifically designed for coding, GitHub Copilot\sidenote{\rurl{github.com/features/copilot}} assists programmers within IDEs and has over a million subscribers\sidenote{\rurl{github.blog/news-insights/research/the-economic-impact-of-the-ai-powered-developer-lifecycle-and-lessons-from-github-copilot}}.
Despite their benefits, AI-generated code can introduce bugs as human-written code \sidecite{Asare2023}, making it crucial to use techniques that detect software errors or certify intended behaviors.

Detecting software errors is mandatory across various contexts, from more traditional safety-critical systems to the latest AI-generated applications, to ensure a correct software behavior.

\section{Software Quality}

Software quality measures how well software meets its requirements.
The most common method to ensure software quality is \emph{testing}.
The correct behavior of software is tested empirically for a finite number of inputs against a set of assertions specifying the functional requirements of the code.
However, testing has inherent limitations.
It can only verify a program against functional requirements, which may be poorly defined and ambiguous, leading to inadequate testing.
Exhaustive testing is impractical, and constraints on time and budget can further impact the process.
Mostly, testing cannot guarantee the absence of bugs\sidenote{``Program testing can be quite effective for showing the presence of bugs, but is hopelessly inadequate for showing their absence.'' -- \textcite{Dijkstra1976}} \sidecite{Dijkstra1976}.
While in some cases deploying software with bugs and relying on patches to fix it is acceptable, \cf{} \reftab{effort-to-fix}, ensuring that software is free of bugs before deployment is necessary to avoid catastrophic consequences in safety-critical systems.

In contrast to testing, \emph{formal methods} provide rigorous mathematical guarantees about software correctness.
The idea of formally verifying software dates back to the late 1960s with program proofs and invariants from \sidetextcite{Floyd1967} and \sidetextcite{Hoare1969}.
Even earlier, formal methods can be traced to the work of \sidetextcite{Church1936} and \sidetextcite{Turing1937} on the foundations of computation.
According to software engineering practices, formal methods should be introduced early in the development lifecycle, enabling the verification of software properties at the design stage.

\begin{center}\em
  Why should formal methods replace other well-known, widely accepted, and user-friendly techniques such as testing?
\end{center}

To answer this question, consider the following examples where testing failed:

\begin{itemize}
\item The Ariane 5 rocket failure in 1996, caused by an integer overflow bug, resulted in a loss of \$370 million\sidenote{\rurl{esamultimedia.esa.int/docs/esa-x-1819eng.pdf}}.
\item The Therac-25 radiation therapy machine malfunctioned due to software bugs, resulting in patient deaths and serious injuries \sidecite{Leveson1993}.
\item The Toyota unintended acceleration case, where a stack overflow resulted in the death of 89 people and a lawsuit of \$1.2 billion\sidenote{\rurl{www.embeddedrelated.com/showarticle/1574.php}}.
\item A round-off error in the Patriot missile system caused the death of 28 people during the Gulf War\sidenote{\rurl{www.ima.umn.edu/~arnold/disasters/patriot.html}}.
\end{itemize}

These cases could have been avoided with formal methods.

Unlike testing, formal methods enable exhaustive search and detection of bugs that testing may miss.
System requirements are translated into formal specifications, which are mathematically verified to ensure the system's behavior aligns with real-world scenarios.
However, Rice's undecidability theorem \sidecite{Rice1953} states that all non-trivial program properties\sidenote{A property is non-trivial if it is not true for all programs or false for all programs.} are undecidable, meaning there is no always terminating algorithm that can decide whether any program satisfies a non-trivial program property.
Consequently, formal methods either sacrifice: \emph{automation}, \emph{soundness}/\emph{termination}, or \emph{completeness}
Based on this, formal methods are classified into three categories \sidecite{Cousot2010} (\reffig{formal-methods-trade-offs}): \emph{theorem provers}, \emph{model checking}, and \emph{static analysis}.

\begin{marginfigure}
  \begin{tikzpicture}[scale=0.8]
    % Draw the triangle
    \draw[thick] (0,0) -- (4,2.5) -- (0,5) -- cycle;

    % Place the vertices with blue squared borders
    \node[draw, fill=white, text width=1.7cm, align=center, draw=white] at (0,0) {\small \textsc{Automation}};
    \node[draw, fill=white, text width=1.6cm, align=center, draw=white] at (4,2.5) {\small \textsc{Soundness}};
    \node[draw, fill=white, text width=1.85cm, align=center, draw=white] at (0,5) {\small \textsc{Completeness}};

    % Place the edges' labels inside the edges
    \node[fill=white, text width=1.18cm, align=center] at (2,1.4) {\small Static Analysis};
    \node[fill=white, text width=1.5cm, align=center] at (0,2.5) {\small Model Checking};
    \node[fill=white, text width=1.3cm, align=center] at (2,3.6) {\small Theorem Provers};
\end{tikzpicture}
  \caption{Trade-offs in formal methods.}
  \labfig{formal-methods-trade-offs}
\end{marginfigure}

Theorem provers \sidecite{Nawaz2019} produce proofs of correctness using interactive tools, also called proof assistants, such as Coq \sidecite{Bertot2004} and HOL Light \sidecite{Harrison2009}, or automatic ones \sidecite{Sutcliffe2001}.
User interaction is ultimately required to guide the proof search in both the interactive and automatic cases.
Theorem provers are complete and sound but not fully automated.

Formal methods based on model checking automatically explore the state space of a program's model to verify whether undesirable states are reachable.
\sidetextcite{Clarke2004} applied model checking to prove the correctness of ANSI-C programs.
However, modern model checker trades termination for automation and completeness, as state-of-the-art model checkers may not terminate.

Static analysis analyzes the program source code at some level of abstraction without user interaction.
This abstraction is sound but incomplete, meaning the analysis may report \emph{false alarms}, \ie, warnings that a correct program may be incorrect.
However, whenever the static analysis certifies the absence of a bug, the program is indeed bug-free.
In formal methods, the most common static analysis techniques are based on \emph{abstract interpretation}.

Abstract Interpretation \sidecite{Cousot1977} is a general theory for approximating program semantics, developed by Patrick and Radhia Cousot in the late 1970s (see \sidecite{Cousot2024} for an historical view).
Their framework is based on the observation that not all computational details are necessary to reason about program properties.
Instead, the program's semantics can be approximated by a simpler, more abstract model that facilitates automatic reasoning.

Over the past decade, abstract interpretation-based static analyses became part of the software development lifecycle of safety-critical systems.
For instance, the \emph{Astrée} static analyzer \sidecite{Blanchet2003} is routinely used to ensure the absence of runtime errors in embedded synchronous C programs for the Airbus A340 and A380.

We provide a formal introduction to abstract interpretation in \refch{abstract-interpretation}.
At the end of that chapter, we will illustrate the main results on a small idealized programming language.

\section{Input Data Usage}

Programming errors in software systems do not always result in crashes or runtime errors.
Sometimes, faulty programs produce plausible yet erroneous outcomes or unsafe behaviors.
Such bugs are hard to spot since they provide no clear indication that something went wrong.
A potential and common source of such errors is the misuse of input data, \ie, when an input variable has an unexpected impact on the program computation compared to the developers' expectations.

A notable example is the Reinhart and Rogoff article “Growth in a Time of Debt” \sidecite{Reinhart2010}, which claimed that economic growth is negatively correlated with public debt.
This article was heavily cited to justify austerity measures worldwide in the following years.
However, in 2013, \sidetextcite{Herndon2014} discovered that the authors had made a mistake in their Excel spreadsheet, leading to the erroneous conclusion.
One of the errors was the incorrect usage of the input value relative to Norway's economic growth in 1964, with an excessive weight in the average growth rate computation.

In data science applications, where software involves long pipelines that filter, merge, and manipulate data, programming errors causing input variables to have more or less influence than expected are likely.
Hence, it is essential to employ techniques that enhance confidence in the usage of input variables for data-driven applications.


In \arefpart{background}, \refch{input-data-usage} formally introduces input data usage, a program property that captures the \emph{qualitative} usage of input data in a program as proposed by \sidetextcite{Urban2018}.
We provide a hierarchy of semantics that precisely captures the input data usage property, abstracting unnecessary details.
Finally, we report an abstract semantics that captures syntactic dependencies between variables from \sidetextcite{Urban2018}, used to approximate the input data usage property soundly.

We extend the property to capture abstractions of output values, similarly to the generalization of non-interference \sidecite{Giacobazzi2018}, discussing relations between the two properties.

\paragraph{Contributions}

In \refch{input-data-usage}, we extend the original definition of the input data usage to capture abstractions of output values, similarly to abstract non-interference \sidecite{Giacobazzi2018}, discussing relations between the two properties.
Such extension blends abstract non-interference with input data usage, providing a definition that works also for non-deterministic programs.


\section{Quantitative Properties}

Typically, program properties are qualitative: a program either satisfies a property or not.
This is not always sufficient to capture the complexity of real-world requirements \sidecite{Smith2007}.
For instance, in program security, one fundamental requirement is protecting sensitive information confidentiality.
Secure information flow analysis questions whether a program could leak information about its secrets.
Noninterference, certifying that a program reveals no information about its secrets, is a classic secure information flow approach.
However, noninterference is too strict for many practical applications.
For example, in a digital election protocol, individual votes should be anonymous, but the final result needs to be revealed.
A password checker should not reveal the password but should indicate whether the password is correct.
These cases represent deliberate violations of noninterference necessary for the program to fulfill its purpose.

To address this limitation, quantitative properties are considered \sidecite{Smith2009}.
The key idea is to accept that a program may violate a property and compare such violation against a threshold.
Programs are classified as \emph{safe} or \emph{unsafe} based on the degree of violation, inducing a classification among programs based on how much safety they provide.

In the Reinhart and Rogoff case,
The error was not whether
the value of Norway's economic growth
was used
in the average computation
but rather how much it was used, \ie,
its impact was much higher than it should have been.
A quantitative analysis would have revealed that the impact of Norway's economic growth was too high, allowing the authors to correct the wrong conclusion.

\subsection{Quantitative Verification of Extensional Properties}[Extensional Properties]


In this thesis, we study formal reasoning techniques to detect input data misuse.
We propose semantics-based static analysis techniques to quantify the impact of input variables on program computation.
In \refch{quantitative-input-data-usage}, we introduce a new formal framework based on abstract interpretation for reasoning about quantitative input data usage properties.
This framework can identify variables with disproportionate impact, certifying intended behavior or revealing potential flaws by matching developers' expectations with actual results.
We characterize the impact of an input variable with a notion of dependency between variables and program outcomes.
Our framework is parametric in the impact definition of choice.
%
We introduce a backward static analysis based on abstract interpretation, parametric in the impact definition, which infers a sound over-approximation of the impact of input variables.
The analysis computes the input states leading to output buckets, applying a computable implementation of the impact on the backward reachability analysis result.
This approach allows end-users to choose the impact that fits their needs, ensuring a targeted and customizable analysis.

\marginnote{\refch{quantitative-input-data-usage} and \refch{showcase} in \arefpart{extensional} are based on the work published at NASA Formal Methods
Symposium (NFM) 2024 \cite{Mazzucato2024b}.}
\marginnote{\formatmargincitation{Mazzucato2024b}}

\refch{showcase} demonstrates the quantitative framework's potential applications by evaluating our static analysis tool, \impatto\sidenote{\label{intro:impatto}\impattourl}, against six use cases.

\marginnote{\refch{quantitative-fairness} and \refch{evaluation-on-neural-networks} in \arefpart{extensional} are based on the work published at the 28th Static Analysis Symposium (SAS) 2021 \cite{Mazzucato2021}.}
\marginnote{\formatmargincitation{Mazzucato2021}}

In \refch{quantitative-fairness}, we extend the quantitative input data usage property to neural networks.
We propose two impact quantifiers for neural networks, addressing the ragged input space and measuring input features' fairness.
We refine the backward analysis to exploit parallel computations for better performance, employing a combination of forward and backward analyses.
The forward pass reduces the backward analysis's combinatorial explosion, partitioning the input space into subregions for easier parallel analysis.
\refch{evaluation-on-neural-networks} demonstrates the effectiveness of our approach on neural networks, showing that our method can identify input features with a disproportionate impact on the network's output, or quantify the fairness of neural networks.



\paragraph{Contributions}
The followings are the contributions of \arefpart{extensional}, containing \cref{ch:quantitative-input-data-usage,ch:showcase,ch:quantitative-fairness,ch:evaluation-on-neural-networks}:

\begin{itemize}
  \item In \refch{quantitative-input-data-usage}, we develop a theoretical framework by abstract interpretation to quantify the impact of input variables by considering three novel impact quantifiers.
  \item In \refch{quantitative-input-data-usage}, we present our static analysis and a possible abstract implementation of the impact instances.
  \item In \refch{showcase} our tool called \impatto showcases our approach against a set of six demonstrative programs.
  \item In \refch{quantitative-fairness}, we present two impact quantifiers for neural networks.
  \item In \refch{quantitative-fairness}, we propose an improved backward analysis that exploits parallel computations and achieves better precision by combining abstract domains.
  \item In \refch{evaluation-on-neural-networks}, we extended both the \impatto{} and \libra\sidenote{\libraurl} tools to evaluate our quantitative analysis on neural networks.
\end{itemize}

\subsection{Quantitative Verification of Intensional Properties}[Intensional Properties]

\marginnote{\arefpart{intensional} is based on the work published at the 31st Static Analysis Symposium (SAS) 2024 \cite{Mazzucato2024c}.}
\marginnote{\formatmargincitation{Mazzucato2024c}}

\arefpart{intensional} focuses on the quantitative verification of intensional properties, \ie, properties that depend on the program's internal behavior, \eg, the number of iterations of a loop.
This part is divided into two chapters: the first one presenting the novel quantitative timing analysis, and the second one showing the experimental evaluation.

In \refch{quantitative-static-timing-analysis}, we consider the number of program iterations as the program outcome, capturing the impact of input variables on the global number of iterations.
This variation is crucial, as programming errors affecting iterations can degrade performance or introduce security vulnerabilities without functional errors.
For instance, unexpected input impacts on runtime could reveal sensitive information \sidecite{Wong2005}, posing security threats.
Even cryptographic programs are vulnerable to timing attacks, depending on implementation choices.
\sidetextcite{Kocher1996} demonstrated that public key cryptographic algorithms, like RSA, are susceptible to timing attacks, potentially leaking secret keys.

Knowing the timing behavior of a program can certify intended behavior or reveal latent flaws by matching developers' expectations with actual program behavior.
For performance optimization, identifying input variables that significantly affect loop iterations helps developers focus on critical code segments \sidecite{Omar2017}.
Consequently, understanding the impact of input variables on runtime is paramount.
In this study, we focus on quantifying input variables' impact on loop iterations as an indicator of runtime behavior.

We leverage global loop bound analysis to derive an over-approximation of the global loop bound, encoding the quantification of input variables' impact as a linear programming problem.
Our approach blends syntactic and semantic information: generating invariants as linear constraints for accuracy and combining global loop bound analysis with syntactic dependency analysis \sidecite{Urban2018} for scalability.

In \refch{sas24-eval}, we present \timesec\sidenote{\timesecurl}, a tool implementing our quantitative timing analysis.
We demonstrate its effectiveness in a real-world cryptographic library, certifying its immunity to timing side-channel attacks by showing no impact of input variables on loop iterations.
Additionally, we evaluate \timesec{} against programs from \svcomp.


\paragraph{Contributions}

The followings are the contributions of \arefpart{intensional}:

\begin{itemize}
  \item In \refch{quantitative-static-timing-analysis}, we propose a static analysis, employing a linear constraint abstract domain, global loop bound analysis, and linear programming encoding to quantify the impact of input variables on loop iterations, and
  \item In \refch{sas24-eval}, we present \timesec\sidenote{\timesecurl}, a tool implementing our quantitative timing analysis, and evaluate it against the \bignum{} cryptographic library\sidenote{\bignumurl} and programs from \svcomp \sidenote{\svcompurl}.
\end{itemize}

\frenchdiv

Related works are discussed at the end of each chapter of \cref{part:extensional,part:intensional}, providing a comprehensive overview of the literature.
At the end of the thesis, in \arefpart{conclusion}, we conclude the thesis with a summary and future work.
