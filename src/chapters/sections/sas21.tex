\chapter{Quantitative Fairness for Neural Networks}
\labch{quantitative-fairness}

In this chapter, we introduce the context of neural network formal analysis, we define formally the concept of feed-forward deep neural networks for classification purposes.
We introduce two quantitative impact notions: the \changesname{} impact notion, which targets the repetitions of changes in the outcome, and the \qlibraname{} impact notion, which measures the amount of bias of a neural network. We then present the abstract implementation of the two impact notions, respectively called $\abstractchangesname$ and $\abstractqlibraname$, and we show how to validate the $\defbound$-bounded impact property for both notions. Finally, we present the parallel analysis for efficient neural network verification of the $\abstractqlibraname$ impact notion.
This chapter is based on the work presented at the 28th Static Analysis Symposium (SAS 2021)~\cite{Mazzucato2021}.

\emph{Dans ce chapitre, nous introduisons le contexte de l'analyse formelle des réseaux neuronaux, et nous définissons formellement le concept de réseaux neuronaux profonds à propagation avant pour des objectifs de classification.
Nous introduisons deux notions d'impact quantitatif : la notion d'impact \changesname{}, qui cible les répétitions de changements dans le résultat, et la notion d'impact \qlibraname{}, qui mesure le degré de biais d'un réseau neuronal. Nous présentons ensuite l'implémentation abstraite de \changesname{} et \qlibraname{}, respectivement appelées $\abstractchangesname$ et $\abstractqlibraname$, et nous montrons comment valider la propriété d'impact bornée par $\defbound$ pour les deux notions. Enfin, nous présentons l'analyse parallèle pour la vérification efficace des réseaux neuronaux selon la notion d'impact $\abstractqlibraname$.
Ce chapitre est basé sur les travaux présentés lors du 28e Symposium sur l'Analyse Statique (SAS 2021)~\sidecite{Mazzucato2021}.}

% \input{src/chapters/extensional/sas21/overview}
% \input{src/chapters/extensional/sas21/changes}
% \input{src/chapters/extensional/sas21/qlibra}
% \input{src/chapters/extensional/sas21/evaluation-changes}
% \input{src/chapters/extensional/sas21/evaluation-qlibra}

\section{Neural Networks}
\labsec{neural-networks}

This section introduces the computational model of a feed forward neural network and how it can be used for classification purposes.

\subsection{Feed-Forward Deep Neural Networks}

A \emph{feed forward deep neural network} is a directed acyclic graph where each node represents a neuron, and each edge represents a connection between neurons.
The nodes are arranged in layers, where the first layer is the input layer ($\inputlayer$), the last layer is the output layer ($\outputlayer$), and the layers in between are called hidden layers ($\hiddenlayers$).
Each layer $\hiddenlayer{i}$ is composed of a set of $\cardinalitynospaces{\hiddenlayer{i}}$ nodes, and is connected to the previous layer $\hiddenlayer{i-1}$ through a weight $\cardinalitynospaces{\hiddenlayer{i}}\times\cardinalitynospaces{\hiddenlayer{i-1}}$-matrix $\weightmatrix{i}$ and a bias $\cardinalitynospaces{\hiddenlayer{i}}$-vector $\biasvector{i}$.
The set of all nodes is denoted by $\networknodes$ and the set of nodes in layer $\hiddenlayer{i}$ is denoted by $\networknodesinlayer{i}$. The $j$-th node in layer $\hiddenlayer{i}$ is denoted by $\node$.
In this thesis we focus on feed forward neural networks used for classification tasks, where each node in the output layer represents a class, and the output of the network is the class yielding the highest value. In total, the network has $\cardinalitynospaces{\outputlayer}$ number of target classes.

An input value is a $\cardinalitynospaces{\inputlayer}$-dimensional vector $\networknodesinlayer{0}$; for simplicity, we assume that the input values are normalized to the interval $[0,1]$.
The value of each hidden and output node is computed by applying an activation function to the weighted sum of the values of the nodes in the previous layer and the bias. The activation function is usually a non-linear function, we consider the \relu{} activation function in this work, which is defined as $\relu(x) = \max(0,x)$. Thus, the value of node $\node$ in layer $\hiddenlayer{i}$ is computed as:
\begin{align*}
  \node = \relu\left(
    \sum_{k}^{\cardinalitynospaces{\hiddenlayer{i-1}}}\weight_{j, k}^{i} \node[i-1][k] + \bias_{j}^{i}
  \right)
\end{align*}
where $\weight_{j, k}^{i}$ is the weight connecting node $\node[i-1][k]$ in layer $\hiddenlayer{i-1}$ to node $\node$ in layer $\hiddenlayer{i}$, and $\bias_{j}^{i}$ is the bias of node $\node$ in layer $\hiddenlayer{i}$. Weights and biases are learned during the training phase of the network. In the following, we consider already trained networks.


\subsection{Classification Task}

In this thesis, we focus on feed forward neural networks used for classification tasks.
That is, given an input vector, the network classifies it into one of the target classes, each represented by a node in the output layer.
The way the network classifies an input vector is by computing the value of the nodes in the output layer, and then selecting the class associated with the node with the highest value, \ie{} $\argmax_{j} \node[\lastlayerindex][j]$.

The classification task is formalized by the means of the output observer $\outputobs$ (\refdef*{output-observer}) which maps the output values of the network to the target classes.
We define the output observer to return $1$ if the index of the node with the highest value is equal to the target class, and $0$ otherwise.
In such a way, when the output state of a trace from the network computation is passed to the output observer, the only non-zero value is the one corresponding to the target class. Formally, the output observer is defined as:
\begin{align*}
  \outputobs(\defstate) \DefeQ \lambda \defvariable.\spacer
  \begin{cases}
    1 & \text{if } \argmax_{j} \defstate(j) = \defvariable \\
    0 & \text{otherwise}
  \end{cases}
\end{align*}
The characterization above shows that two different states of the network can be distinguished by the output observer if and only if they are associated with different target classes, yielding in fact different outcomes.


\begin{example}
  Consider a simple neural network with two input and two output variables.
  The weights and biases connecting the input with the output layer are irrelevant for this example.
  Therefore, the network states are defined as $\defstate = \setdef{\langle x_{0, 0}, x_{0, 1}, x_{1, 0}, x_{1, 1} \rangle}{x_{0, 0}, x_{0, 1}, x_{1, 0}, x_{1, 1} \in \R}$. For simplicity, we assume all the variables to be real\sidenote{often neural networks normalize inputs in the interval [0, 1].}.
  Given, for instance, the network state $\langle 0, 1, 0, 1 \rangle$, the output observer $\outputobs$ returns the state $\outputobs(\defstate) = \langle 0, 0, 0, 1 \rangle$ to indicate that the target class is the second one, \cf{} the one relating $x_{1, 1}$.
  Given instead the network state $\langle 0.5, 1, 0.7, 0.2 \rangle$, the output observer returns the state $\outputobs(\defstate) = \langle 0, 0, 1, 0\rangle$ to indicate that the target class is the first one (the first two variables are the input variables), and so on.
\end{example}

Note that, the output observer always maps to zero the values of neural-network nodes that do not belong to the output layer.

\section{Quantitative Impact Notions}
\labsec{quantitative-impact-notions}

This section elaborates on quantitative notions that can be used to measure the influence of input variables on the output of a neural network.
Namely, we introduce the \changesname{} and \qlibraname{} impact notions, which are specifically designed to handle the irregular input space produced by neural-network models.

\subsection{The \changesname{} Impact Notion}[\changesname]
\labsec{changes-impact-notion}


The \changesname{} impact notion is designed to overcome the limitations of the impact notions defined in the previous chapter when applied in the context of neural networks.
Indeed, in the presence of neural networks, the input space is generally irregular, and all the possible input variations lead to all the possible outcomes.
Therefore, the impact notions defined in the previous chapter would not be useful as they measure the impact of input variables based on the number (\eg{} \outcomesname{}) or the magnitude (\eg{} \rangename{}) of the output values; even \qusedname{} would be meaningless in this setting as all the classification targets are often reachable by all the input values.
Therefore, these metrics would not provide any meaningful information about how the input variables influence the network's outcome.

\begin{example}
  \begin{marginfigure}
  \begin{tikzpicture}[scale=0.9]
    % Grid
    % \draw[help lines, color=gray!30, dashed] (-0.1,-0.1) grid (4.1,4.1);
    % x-axis ticks
    % \foreach \x in {-4,-3,-2,-1,0,1,2,3,4}
    %     \draw (\x+5,0.1) -- (\x+5,-0.1) node[below] {\x};
    % % y-axis ticks
    % \foreach \y in {1,2,3}
    %     \draw (0.1,\y) -- (-0.1,\y) node[left] {\y};
    % Polyhedra
    \fill[color=seabornYellow, opacity=0.5] (1,1.75) -- (2,2.75) -- (2.5,1.75) -- (3,2.75) -- (3,4) -- (2,4) -- cycle;
    % \draw[color=seabornYellow, ultra thick] (1,1.75) -- (2,2.75) -- (3,2.75) -- (3,4) -- (2,4) -- cycle;
    % Polyhedra
    \fill[color=seabornGreen, opacity=0.5] (0,2.25) -- (0.5,2.25) -- (1,1.75) -- (2,4) -- (0,4) -- cycle;
    \draw[color=seabornGreen, ultra thick] (0,2.25) -- (0.5,2.25) -- (1,1.75) -- (2,4) -- (0,4) -- cycle;
    \fill[color=seabornGreen, opacity=0.5] (3,2.75) -- (4,1.5) -- (4,4) -- (3,4) -- cycle;
    \draw[color=seabornGreen, ultra thick] (3,2.75) -- (4,1.5) -- (4,4) -- (3,4) -- cycle;
    % Polyhedra
    \fill[color=seabornRed, opacity=0.5] (0,0) -- (4,0) -- (4,1.5) -- (3,2.75) -- (2.5,1.75) -- (2,2.75) -- (1,1.75) -- (0.5,2.25) -- (0,2.25) -- cycle;
    \draw[color=seabornRed, ultra thick] (0,0) -- (4,0) -- (4,1.5) -- (3,2.75) -- (2.5,1.75) -- (2,2.75) -- (1,1.75) -- (0.5,2.25) -- (0,2.25) -- cycle;
    % Nodes
    % \fill[color=seabornRed] (0+1,0+1) circle[radius=2pt];
    % \node[above left] at (0+1,0+1) {$3$};
    % x-axis
    \draw[->,ultra thick] (0,0)--(4.3,0) node[below]{$x$};
    \draw[ultra thick] (0,4)--(4,4);
    % y-axis
    \draw[->,ultra thick] (0,0)--(0,4.3) node[left]{$y$};
    \draw[ultra thick] (4,0)--(4,4);

    \draw[dashed] (0,2.1) node[left] {$y_0$} -- (4,2.1);
    \draw[dashed] (1.75,0) node[below] {$x_0$} -- (1.75,4);
    % little dot in the intersection x_0 y_0
    \fill[color=black] (1.75,2.1) circle[radius=2pt];
  \end{tikzpicture}
    \caption{Input space with two input variables ($x$ and $y$) and three possible outcomes (green, yellow, red).}
    \label{fig:irregular}
  \end{marginfigure}
  Consider a simple neural network with two input variables $x$ and $y$, and three possible outcomes, denoted by the colors green, yellow, and red.
  A potential input space of such a model is represented in \reffig{irregular}, indeed each outcome is reachable by the portion of the input space that is colored with the corresponding color.
  In this case, the \outcomesname{} impact notion would not be useful as all the outcomes are reachable by perturbations of any input value. Consider for example the point $(x_0, y_0)$ in the input space of outcome red, by applying a perturbation of one axis, the outcome can change to green or yellow, for both axes. Thus, the impact of both $x$ and $y$ is maximal, \cf{} $\outcomesname_x = \outcomesname_y = 3$.
  A similar reasoning applies to the \rangename{} or \qusedname{} impact notions, hence neither they cannot provide any insight.

  On the other hand, we notice that one way to discriminate which input variable is more impactful is to consider the number of times the classification changes when the input variables are modified.
  To this end, we develop a quantitative notion, called \changesname{} impact notion, that measures exactly this property.
\end{example}


The \changesname{} impact notion is designed to count how many times the network outcome changes by modification in the value of the input variables $\definputvariables$.
Notably, we recall similarities with the previously defined $\outcomesname$ impact notion: in this case, we consider changes in the outcome \emph{with repetitions}, that is, if two different variations in $\definputvariable$ result in the same change in outcome, it counts as double change.
The higher the number of changes in the outcome, the greater the influence on the program outcome.
Therefore, this notion demonstrates its effectiveness when the same outcomes are reachable by multiple variations.
Intuitively, such situation often arises in the presence of neural networks, where generally all the possible input variations lead to every possible outcome.
Thus, counting the repetitions is a potential solution to define a meaningful impact definition for neural networks.


\begin{example}
  Consider the input point $(x_0, y_0)$ in the input space of the neural network in \reffig{irregular}.
  By applying a perturbation of the $x$-axis, the outcome can change to green or yellow multiple times, a higher number of changes in the outcome is observed compared to the $y$-axis.
\end{example}


In practice, the \changesname{} impact definition considers variations in the value of input configurations that do not belong to the same \emph{continuous region}, containing no gaps or interruptions.
We first define the function $\segments$, which takes as input a set of traces $\defsetoftraces$ and an output value $\defoutput$.
This function partitions the set of traces $\defsetoftraces$ into continuous subsets with respect to the input variables $\definputvariables$.
Each subset $\defsetoftraces'$ satisfies three conditions: (1) all the traces in $\defsetoftraces'$ share the same output value $\defoutput$, (2) for any two traces in $\defsetoftraces'$, there is no other trace
in $\defsetoftraces$ with an input value between the two traces leading to a different output value, and (3) the subset is maximal, that is, there is no other trace in $\defsetoftraces$ that can be added to $\defsetoftraces'$ without violating the first two conditions.
The function $\segments$ is defined as follows:


\begin{definition}[Segments of Continuous Regions]\labdef{segments}
  Let $\definputvariables\in\inputvariables$ be the set of input variables of interest.
  Given a set of traces $\defsetoftraces\in\tracetype$ and an output value $\defoutput\in\stateandbottom$, the function $\segments\in\pair\tracetype\stateandbottom\to\setof\tracetype$ is defined as:
  \begin{align*}
    \segments(\defsetoftraces, \defoutput) &\DefeQ
      \setdef{
        \defsetoftraces' \in \phi(\defsetoftraces)}{
          \foralldef{\defsetoftraces''\supset\defsetoftraces'}{
            \defsetoftraces''\notin\phi(\defsetoftraces)
          }
        }\\
    \text{where } \phi(\defsetoftraces) &\DefeQ
      \setdef*{
        \defsetoftraces'\subseteq\defsetoftraces
      }{
        \forall \deftrace\in\defsetoftraces'.\spacer \outputobs(\retrieveoutput{\deftrace}) = \defoutput \LanD \\
        \forall \deftrace, \deftrace'\in\defsetoftraces'.\spacer \exists \deftrace''\in\defsetoftraces.\spacer \\
          \quad\retrieveinput{\deftrace}(\definputvariables) \le \retrieveinput{\deftrace''}(\definputvariables) \le \retrieveinput{\deftrace'}(\definputvariables) \implies \deftrace'' \in \defsetoftraces'
      }
  \end{align*}
\end{definition}

Note that, the auxiliary function $\phi$ partitions the set of traces $\defsetoftraces$ into subsets that satisfy the first two conditions: (1) all the traces in the subset share the same output value $\defoutput$, and (2) for any two traces in the subset (\cf{} $\outputobs(\retrieveoutput{\deftrace}) = \defoutput$), there is no other trace in $\defsetoftraces$ with an input value between the two traces leading to a different output value (\cf{} $\retrieveinput{\deftrace}(\definputvariables) \le \retrieveinput{\deftrace''}(\definputvariables) \le \retrieveinput{\deftrace'}(\definputvariables) \implies \deftrace'' \in \defsetoftraces'$).
The function $\segments$ then returns the maximal subsets (3) that satisfy the first two conditions.
To better illustrate how the function $\segments$ works, consider the following example.

\begin{example}
  Let us consider the set of traces from the neural network in \reffig{irregular} with $y=y_0$, we call this set $\defsetoftraces$.
  The function $\segments$ partitions the set of traces $\defsetoftraces$ into three subsets, each containing the traces leading to the same output value.
  \denis{Illustration of the segments function on the line with $y = y_0$.}
\end{example}

Formally, \changesname{} is defined as the maximum, for each input configuration, of the number of continuous regions in which the output value changes.
In words, a set of input variables $\definputvariables$ has a high impact on the network outcome if the output value changes in many continuous regions when the input variables are modified.


\begin{definition}[\changesname]\labdef{changes}
  Given a set of input variables of interest $\definputvariables\in\setof\inputvariables$, and an output observer $\outputobs$,
  the quantity $\changes\in\tracetype\to\Nplus$ is defined as:
  \begin{align*}
    \changes(\defsetoftraces) &\DefeQ
      \sup_{\definput\in\reducedstate}
        \sup_{\defoutput\in\stateandbottom}
          \cardinality{Q_{\definputvariables, \definput, \defoutput}} \\
    \text{where } Q_{\definputvariables, \definput, \defoutput} &\DefeQ
      \bigsetjoin_{\defoutput' \in \stateandbottom\setminus\{\defoutput\}}
        \segments(
          \setdef{\deftrace\in\defsetoftraces}{\retrieveinput\deftrace \stateeq{\inputvariableswithoutw} \definput}, \defoutput'
        )
  \end{align*}
\end{definition}
The auxiliary set $Q_{\definputvariables, \definput, \defoutput}$ contains the set of continuous regions leading to an output value different from $\defoutput$.
Additionally, $\changes$ requires the set of traces $\defsetoftraces$ to be deterministic, that is, for each input configuration, there is only one output value. Such a requirement is necessary to ensure that segments are well-defined, as the function $\segments$ partitions the input space into continuous regions leading to the same output value. Otherwise, in a portion of input space where the output value is not deterministic, the number of possible outcomes changes would be infinite.
Nevertheless, since we consider neural networks for classification tasks in this chapter, the output value is deterministic for each input configuration, and thus the set of traces $\defsetoftraces$ is deterministic.
\denis{Fix above paragraph: whenever continuous regions have non-deterministic output values, the number of possible outcomes changes would be infinite.}

\begin{example}
  \denis{The changes function applied to the neural network in \reffig{irregular}.}
\end{example}


\begin{lemma}[\changesname{} is Monotonic]
  \lablemma{changes-monotonic}
For all set of traces $\defsetoftraces, \defsetoftraces'\in\tracetype$, it holds that:
  \begin{align*}
    \defsetoftraces \subseteq \defsetoftraces' \ImplieS \changes(\defsetoftraces) \le \changes(\defsetoftraces')
  \end{align*}
\end{lemma}
\begin{proof}
  The proof is based on the observation that more traces in $\defsetoftraces'$ can only increase the number of continuous regions, never a lower amount.
  Hence, the number of continuous regions leading to a different output (\cf{} $Q_{\definputvariables, \definput, \defoutput}$) can only increase with more traces.
  We conclude that $\changes(\defsetoftraces) \le \changes(\defsetoftraces')$.
\end{proof}

We show the validation of the $\defbound$-bounded impact property when instantiated with the $\changesname$ impact notion,
we call such property $\boundedchanges$.

\siderefbox{def}{output-abstraction-semantics}
\begin{lemma}[$\boundedchanges$ Validation]\lablemma{changes-validation}
  \begin{align*}
    \collectingsemantics \subseteq \BOUNDEDCHANGES \IfF \outputsemantics \subseteq \outputabstraction(\dependencyabstraction(\BOUNDEDCHANGES))
  \end{align*}
\end{lemma}
\begin{proof}
  The $\changesname$ impact notion does not consider the intermediate states, in fact, it only employs the first state in the definition of $Q_{\definputvariables, \definput, \defoutput}$ and the last one in the definition of $\segments$.
  Thus, the abstraction to dependencies does not affect the validation of the property.
  Furthermore, even handling the output abstraction at the semantic level, by abstracting output states to abstract output states, does not affect the validation of the property as the $\changesname$ impact notion already abstracts the output values before comparing to the given output $\defoutput$, \cf{} $\outputobs(\retrieveoutput{\deftrace}) = \defoutput$ in \nrefdef{segments}.
\end{proof}

\reflemma{changes-monotonic} and \reflemma{changes-validation} are of significant importance as they show that the $\changesname$ impact notion can be used to certify that a program has impact of \emph{at most} $\defbound$, meaning that the program output changes at most $\defbound$ times when the input variables vary.


\subsection{The \qlibraname{} Impact Notion}[\qlibraname]
\labsec{qlibra-impact-notion}

The second notion introduced in this section is the \qlibraname{} impact notion.
Notably, this notion is designed to quantify the amount of neural-network's input space that does not contain bias.
A network is fair whenever the classification determined by a model does not depend on the ``sensitive'' input variables.
In our setting, the sensitive input variables are the represented by the set of input variables $\definputvariables$ and quantifying the amount of bias is equivalent to measuring the influence of the input variables $\definputvariables$ on the network outcome.
To this end, we define the \qlibraname{} impact notion as the volume of input space that is not able to change the model classification by perturbation of the input variables $\definputvariables$.
The higher the volume, the lower the amount of space that is prone to bias, and thus the higher the fairness of the model.

In practice, we collect the input space, without the input variables $\definputvariables$ to account for any possible permutations of their input values, where the variables $\definputvariables$ do not influence the network outcome.
% To do so, we employ the $\unusediowrapper$ predicate to check whether a subset of the given set of traces $\defsetoftraces$ is not able to change the network outcome.
% Among all the possible subsets, we consider the maximal one, that is, the one that cannot be extended without changing the network outcome.
To do so, we retrieve the input values of traces that do not change the network outcome when the input variables $\definputvariables$ are modified, similarly to the $\unusediowrapper$ predicate.
We determine the volume of this set of points by applying the standard volume operation inherent to metric spaces.
Formally, the \qlibraname{} impact notion is defined as follows:

\begin{definition}[\qlibraname]\labdef{qlibra}
  Given a set of input variables of interest $\definputvariables\in\setof\inputvariables$, and an output descriptor $\outputobs$,
  the quantity $\qlibra\in\tracetype\to[0, 1]$ is defined as:
  % \begin{align*}
  %   \qlibra(\defsetoftraces) &\DefeQ
  %       \volume(\bigsetjoin \setdef{
  %         \defsetoftraces' \setmeet \defsetoftraces''
  %       }{
  %         \defsetoftraces'\in Q \land \defsetoftraces''\in Q \setminus \{\defsetoftraces'\}
  %       }) \\
  %   \text{where } Q &\DefeQ
  %     \setdef{
  %       \setdef{
  %         \retrieveinput{\deftrace}(\inputvariableswithoutw)
  %       }{
  %         \deftrace \in \defsetoftraces \land \outputobs(\retrieveoutput{\deftrace}) = \defoutput
  %       }
  %     }{
  %       \defoutput\in\stateandbottom
  %     }
  % \end{align*}
  % \begin{align*}
  %   &\qlibra(\defsetoftraces) \DefeQ
  %       \volume(\setdef{\retrieveinput{\deftrace}(\inputvariableswithoutw)}{\deftrace\in\defsetoftraces'}) \\
  %   &\quad\text{where } \defsetoftraces' \subseteq \defsetoftraces \text{ such that } \forall \defsetoftraces'' \supseteq \defsetoftraces'.\spacer
  %     \unusediowrapper(\defsetoftraces') \land \neg\unusediowrapper(\defsetoftraces'')
  % \end{align*}
  \begin{align*}
    &\qlibra(\defsetoftraces) \DefeQ \\
    &\quad \volume\left(\setdef*{\retrieveinput{\deftrace}(\inputvariableswithoutw)}{
      \deftrace\in\defsetoftraces \LanD \forall \defvalue\in\values.\spacer
      \retrieveinput\deftrace(\definputvariables) \neq \defvalue \implies \\
      \exists \deftrace'\in\defsetoftraces.\spacer
      \retrieveinput{\deftrace'}(\definputvariables) = \defvalue \LanD \retrieveinput\deftrace \stateeq{\inputvariableswithoutw} \retrieveinput{\deftrace'} \LanD \\
      \quad \outputobs(\retrieveoutput{\deftrace}) = \outputobs(\retrieveoutput{\deftrace'})
    }\right)
  \end{align*}
\end{definition}

In other words, the \qlibraname{} quantifies the volume of the biggest set of traces $\defsetoftraces' \subseteq \defsetoftraces$ that does not contain bias, \ie{} where the predicate $\unusediowrapper$ holds.
Indeed, the \qlibraname{} impact notion could be rewritten as:
\begin{align*}
  &\qlibra(\defsetoftraces) \spacearound= \\
     &\quad \volume(\setdef{\retrieveinput{\deftrace}(\inputvariableswithoutw)}{
        \unusediowrapper(\setdef{\deftrace'\in\defsetoftraces}{\retrieveinput{\deftrace'}(\inputvariableswithoutw) = \retrieveinput{\deftrace}(\inputvariableswithoutw)})
      })
\end{align*}

Such a definition is important because it highlights the relation between the \qlibraname{} impact notion and the $\unusediowrapper$ predicate.
In fact, the \qlibraname{} impact notion quantifies the volume of input space where the $\unusediowrapper$ predicate holds.


\begin{example}
  \denis{Example of the qlibra function on\reffig{irregular}.}
\end{example}

As noticed for the previous impact notion $\changesname$, neural-network models produce deterministic set of traces.
Hence, as the goal of this impact notions is to measure the impact of input variables in the context of neural networks, we can require the set of traces $\defsetoftraces$ to be deterministic without loss of generality.

\begin{lemma}[\qlibraname{} is Decreasing Monotonic]
  \lablemma{qlibra-monotonic}
For all deterministic set of traces $\defsetoftraces, \defsetoftraces'\in\tracetype$, it holds that:
  \begin{align*}
    \defsetoftraces \subseteq \defsetoftraces' \ImplieS \qlibra(\defsetoftraces) \ge \qlibra(\defsetoftraces')
  \end{align*}
\end{lemma}
\begin{proof}
  The proof is based on the observation that more traces in $\defsetoftraces'$ can only increase the volume of bias space as, in the worst case scenario, the added traces are the ones able to change the network outcome.
  In fact, \refprop{ani-predicate-equivalence} proves that the $\unusediowrapper$ predicate is equivalent to the $\aniwrapper$ predicate whenever the given set of traces is deterministic, which is decreasing monotonic in the amount of traces.
  Hence, the volume of the set of points leading to different output values can only increase with more traces, hence the volume of fair space decreases.
  We conclude that $\qlibra(\defsetoftraces) \ge \qlibra(\defsetoftraces')$.
\end{proof}

We show the validation of the $\defbound$-bounded impact property when instantiated with the $\qlibraname$ impact notion,
we call such property $\boundedqlibra$.

\siderefbox{def}{output-abstraction-semantics}
\begin{lemma}[$\boundedqlibra$ Validation]\lablemma{qlibra-validation}
  \begin{align*}
    \collectingsemantics \subseteq \BOUNDEDQLIBRA \IfF \outputsemantics \subseteq \outputabstraction(\dependencyabstraction(\BOUNDEDQLIBRA))
  \end{align*}
\end{lemma}
\begin{proof}
  The $\qlibraname$ impact notion employs the $\unusediowrapper$ predicate to determine the volume of the input space that does not contain bias.
  Thus, this proof directly follows from \refthm{output-validation}.
\end{proof}

\reflemma{qlibra-monotonic} and \reflemma{qlibra-validation} are of significant importance as they show that the $\qlibraname$ impact notion can be used to certify that a program has impact of \emph{at least} $\defbound$, meaning that the input variables $\definputvariables$ of a network are fair for at least $\defbound$ fraction of the input space.

For clarity, we unfold the $\unusediowrapper$ predicate in the definition of the \qlibraname{} impact notion (assuming the set of traces $\defsetoftraces$ is deterministic).
From \refprop{ani-predicate-equivalence}, we notice that the $\unusediowrapper$ predicate is equivalent to the $\aniwrapper$ predicate whenever the set of traces is deterministic, thus obtaining the following definition:

\begin{align*}
  &\qlibra(\defsetoftraces) \\
    &\quad\spacearound=
    \volume\left(\setdef*{\retrieveinput{\deftrace}(\inputvariableswithoutw)}{
      \deftrace\in\defsetoftraces \LanD \forall \deftrace' \in \defsetoftraces.\spacer \\
      \retrieveinput{\deftrace} \stateeq{\inputvariableswithoutw} \retrieveinput{\deftrace'} \implies \outputobs(\retrieveoutput{\deftrace}) = \outputobs(\retrieveoutput{\deftrace'})
    }\right)
\end{align*}

Furthermore, we could also devise a notion that reverse the amount of bias, that is, the volume of the input space that contains bias.

\begin{align*}
  &\qlibra(\defsetoftraces) \\
    &\quad\spacearound=
    1 - \volume\left(
      \setdef*{\retrieveinput{\deftrace}(\inputvariableswithoutw)}{
        \deftrace\in\defsetoftraces \LanD \exists \deftrace' \in \defsetoftraces.\spacer \\
        \retrieveinput{\deftrace} \stateeq{\inputvariableswithoutw} \retrieveinput{\deftrace'} \LanD \outputobs(\retrieveoutput{\deftrace}) \neq \outputobs(\retrieveoutput{\deftrace'})
      }
      \right)
\end{align*}



\section{Quantitative Analysis of Neural Networks}
\labsec{quantitative-analysis-neural-networks}

\marginnote{\denis{Is it clear that $\changesname$ requires an exact semantics because otherwise non-determinism would imply a bound of $+\infty$? Instead, $\qlibraname$ prefers an exact semantics to not drop precision.}}

This section presents the abstract implementations of the \changesname{} and \qlibraname{} impact notions, respectively called $\abstractchangesname$ and $\abstractqlibraname$.
We show how to validate the $\defbound$-bounded impact property for both notions.


\subsection{Abstract Implementation \texorpdfstring{$\abstractchanges$}{Abstract Changes}}[Abstract \texorpdfstring{$\abstractchanges$}{Changes}]

In this section, we introduce $\abstractchanges$ as a sound implementation of $\changes$.
First, we describe the implementation, then we present the validation of the $\defbound$-bounded impact property $\boundedchanges$.

The underlying idea is to gather together abstract elements that represent distinct continuous regions.
To this end, any convex abstract domains, such as polyhedra, octagons, or intervals introduced in the background (\refsec{abstract-domains}), fall short in representing multiple distinct continuous regions as they would also include the points in between.
Therefore, the abstract domain $\abstractdomain$ used in the backward analysis $\backwardsemanticsnoparam$ needs to employ a notion of disjunctive sets, which allows us to represent sets of distinct continuous regions.
We leverage the \textit{disjunctive polyhedra abstract domain} $\disjunctivepolyabstractdomain$, defined as
$
  \langle \disjunctivepolyabstractdomaintype, \disjunctivepolyabstractdomainsubseteq \rangle
$, where $\polyabstractdomain$ represents the \textit{convex polyhedra abstract domain}~\sidecite{Cousot1978} and $\disjunctivepolyabstractdomaintype$ is the set of all finite subset of $\polyabstractdomain$.
From the polyhedra domain $\polyabstractdomain$, the function $\abstractdomainproject$ computes the Fourier-Motzkin elimination algorithm~\sidecite{Dantzig1973}.
Specifically, $\abstractdomainproject$ takes as input a set of variables $\definputvariables$ and a polyhedron in $d$-dimensions where $d \ge \cardinalitynospaces{\definputvariables}$, returning a polyhedron in $(d-\cardinalitynospaces{\definputvariables})$-dimensions, removing the variable $\definputvariables$.

The function $\abstractchanges$ takes as input the variables of interest $\definputvariables$, $\numberofbuckets$ output buckets $\buckets\in\vectorbuckets$, and $\numberofbuckets$ disjunctions of polyhedra $\prefrombucket\in\disjunctivepolyabstractdomaintype^\numberofbuckets$ obtained from the backward pre-analysis.
For clarity, we access each polyhedron and disjunctions of polyhedra via indexing as in a matrix-based structure, that is, $\prefrombucket=\{\{P_{1,1}\vee \dots\vee P_{1,p}\},\dots,\{P_{n,1}\vee \dots\vee P_{n,q}\}\}$ where $p = \cardinalitynospaces{\prefrombucket[1]}$ and $q = \cardinalitynospaces{\prefrombucket[n]}$. For instance, $\prefrombucket[j]$ refers to the disjunction of polyhedra $\{P_{j,1}\vee \dots\vee P_{j,k}\vee \dots\}$, for $j\le n$, and $\prefrombucket[{j, k}]$ refers to the polyhedron $P_{j,k}\in\polyabstractdomain$.
The projection of disjunctions of polyhedra applies, in turn, the polyhedron projection to each polyhedron in the disjunction, then collects the projected polyhedra in a disjunction of polyhedra, \ie{} $\abstractdomainproject(\prefrombucket \in \disjunctivepolyabstractdomaintype) \defeq \bigvee_{k \le \cardinalitynospaces{\prefrombucket}} \abstractdomainproject(\prefrombucket[j, k])$.

Computationally speaking, the function $\abstractchanges$ projects away the input variables $\definputvariables$ from each polyhedron $\prefrombucket[{j, k}]$.
The projected polyhedra represent regions where $\definputvariables$ ranges on all possible values, considering all potential variations of this variable.
The function $\intersectallfunction$ gathers the set of indexes $J$, also called the connected components, where the projected polyhedra intersect.
The underlying idea is that each connected component corresponds to the set of continuous regions reachable through variations of $\definputvariables$.
% Note that, each connected component is implemented as a \textit{multiset} \denis{no explaination of why using a multiset}, \ie, a set that allows multiple instances for each of its elements.
% This allows us to later exclude regions leading to the same bucket.
%
Finally, $\abstractchanges$ determines the maximum count of changes across all connected components $J$ and buckets $\buckets$.
It counts the number of indices $l$ in each connected component $J$ where $k$ is not equal to $j$, thus excluding the polyhedra leading to the same output bucket $j$.

\begin{definition}[$\abstractchanges$]\labdef{abstractchanges}
  We define $\abstractchanges\in\pair\vectorbuckets\vectorbuckets\to\valuesposplus$ as:
  \begin{align*}
    &\abstractchanges(\presfrombuckets, \buckets) \DefeQ \\
      &\quad \max
      \setdef{
        \max_{j \le \numberofbuckets} \cardinalitynospaces{\setdef{l \in J}{l \neq j}}
      % \\ &\qquad\quad
      }{
        J \in \intersectallfunction((\abstractdomainproject(\prefrombucket))_{j\le\numberofbuckets})
      }
  \end{align*}
\end{definition}

Before proceeding with the soundness proof of $\abstractchanges$, we recall the requirements on the concrete impact notion $\changes$, namely, the requirement on determinism.
Such a requirement is necessary to ensure a meaningful quantity of changes in the outcome, otherwise the number of changes would be infinite in the presence of continuous regions with non-deterministic output values.
Equivalently, in the abstract, any over-approximation from the backward analysis that overlaps different preconditions $\prefrombucket$ would lead to an infinite number of changes.
To this end, we require the backward analysis to be exact: sound and \emph{complete}.
The soundness ensures that the backward analysis does not miss any possible behavior, while the completeness ensures that the backward analysis does not introduce any spurious behavior.
In addition to \refdef*{sound-over-approximation}, we require the following completeness condition on the backward analysis:

\begin{definition}[Complete Under-Approximation]\labdef{complete-under-approximation}
  For all programs $\defprogram$, and output bucket $\bucket\in\abstractdomain$, the family of semantics $\backwardsemanticsnoparam$ is a \textup{complete under-approximation} of the output-abstraction semantics $\outputsemantics$
  when it holds that:
  \[\reducedoutputsemantics \SupseteQ \backwardconcretization(\backwardsemantics)\bucket\]
\end{definition}

Whenever the backward semantics $\backwardsemantics$ is both sound and complete, it yields an exact semantics.

\begin{lemma}[Exact Backward Semantics]\lablemma{exact-backward-semantics}
  Whenever the backward semantics $\backwardsemantics$ is sound and complete, it holds that:
  \[\reducedoutputsemantics \spacearound= \backwardconcretization(\backwardsemantics)\bucket\]
\end{lemma}
\begin{proof}
  Trivially follows from the definitions of soundness (\refdef{sound-over-approximation}) and completeness (\refdef{complete-under-approximation}).
\end{proof}

Note that, whenever the given program is deterministic, the traces concretized from the backward analysis are deterministic as well.
With the exactness of the backward analysis, we show that $\abstractchanges$ is a sound implementation of $\changes$.

\begin{lemma}[$\abstractchanges$ is a Sound Implementation of $\changes$]\lablemma{abstractchanges-is-sound}
  Let $\definputvariables\in\variables$ be the input variable of interest, $\abstractdomain$ the abstract domain, $\backwardsemanticsnoparam$ the family of semantics, and $\buckets\in\vectorbuckets$ the starting output buckets.
  Whenever the following conditions hold:
  \begin{enumerate}[label=(\roman*)]
    \item \label{nioa1} $\buckets$ covers the subset of potential outcomes, \cf{} \refdef*{covering}[*-2],
    \item \label{nioa2} $\buckets$ is compatible with $\outputobs$, \cf{} \refdef*{compatibility}[*4],
    \item \label{nioa3} $\backwardsemanticsnoparam$ is an exact backward semantics, \cf{} \reflemma{exact-backward-semantics}, and
    \item \label{nioa4} $\abstractdomainproject$ is sound, \cf{} \refdef*{soundness-project}[*8];
  \end{enumerate}
  then, $\abstractchanges$ is a sound implementation of $\changes$.
\end{lemma}
\begin{proof}
  \denis{todo}
\end{proof}

\denis{Maybe a recap of the exact backward analysis does not scale well but as a first step it is a good start.}

\subsection{Abstract Implementation \texorpdfstring{$\abstractqlibra$}{Abstract QLibra}}[Abstract \texorpdfstring{$\abstractqlibra$}{QLibra}]
\labsec{abstract-qlibra}


% We assume $\abstractdomain$ is equipped with an additional abstract operator $\abstractdomainvolume\in\abstractdomain\to[0, 1]$, which returns the volume of the given abstract element normalized in the interval $[0, 1]$.
% The abstract implementation $\abstractqlibra$ is defined as the volume of the intersecting abstract regions leading to different output buckets.
% Specifically, the volume is computed by first projecting away the input variables $\definputvariables$ from all the given abstract values resulting from the backward analysis, \cf{} $\presfrombuckets$.
% Then, it collects together all the possible pairwise intersections among the projected abstract values to find the portion of input space leading to different output buckets only via variations of the input variables $\definputvariables$.
% Assuming that all the input variables are bounded in $[0, 1]$, which is a common practice in neural networks, the volume of the abstract element is normalized in the interval $[0, 1]$.

% \begin{example}
%   In the context of the interval domain, where each input variable is related to a possibly unbounded lower and upper bound, $\abstractdomainvolume(\langle \defvariable \mapsto [2, 4]\rangle) = 2$.
%   On the other hand, whenever the input abstract element is unbounded, the size is $+\infty$, \eg{} $\abstractdomainvolume(\langle \defvariable \mapsto [0, +\infty]\rangle) = +\infty$.
%   The function $\abstractdomainvolume$ expects only a single variable to be constrained in the abstract domain, or in other words, only one variable is allowed to be not $\top$.
% \end{example}

% The abstract range $\abstractqlibra$ first projects away the input variables $\definputvariables$ from all the given abstract values.
% Then, it collects all the possible intersections among the projected abstract values.
% These intersections represent concrete input configurations where variations on the values of $\definputvariables$ \emph{may} lead to changes of program outcome, from a bucket to another.
% All the possible combination of intersections are joined together to find the maximum range of the extreme values of the buckets.
% Formally, the abstract implementation $\abstractqlibra$ is defined as follows:

% \begin{definition}[$\abstractqlibra$]\labdef{abstractqlibra}
%   We define $\abstractqlibra\in\pair\vectorbuckets\vectorbuckets\to[0, 1]$ as:
%   \begin{align*}
%     &\abstractqlibra(\presfrombuckets, \buckets) \DefeQ \\
%       &\quad \abstractdomainvolume\left(
%         \bigjoin_{
%           J \in \intersectallfunction((\abstractdomainproject(\prefrombucket))_{j\le\numberofbuckets})
%         }
%           \setdef{
%             \prefrombucket[j] \abstractdomainmeet \prefrombucket[k]
%           }{
%             j, k \in J \land j \neq k
%           }
%       \right)
%   \end{align*}
% \end{definition}

% \begin{example}
%   \denis{Example of the abstractqlibra function on the previous network space.}
% \end{example}

% To prove that $\abstractqlibra$ is a sound implementation of $\qlibra$, we require the following soundness condition on the abstract operator $\abstractdomainvolume$ to ensure that the abstract volume is always greater than the concrete one.

% \begin{definition}[Soundness of \texorpdfstring{$\abstractdomainvolume$}{Volume}]\labdef{soundness-volume}
%   Given an abstract value $\defstate^\natural\in\abstractdomain$ and the set of input variables of interest $\definputvariables\in\inputvariables$, it holds that:
%   \[\abstractdomainvolume(\defstate^\natural) \GE \cardinality{\setdef{\retrieveinput{\defstate}(\definputvariables)}{\defstate\in\abstractdomainconcretization(\defstate^\natural)}}\]
% \end{definition}

% The next result shows that the abstract impact $\abstractqlibra$ is a sound over-approximation of the concrete impact $\qlibra$, \cf{} \refdef{qlibra}.

% \begin{lemma}[$\abstractqlibra$ is a Sound Implementation of $\qlibra$]\lablemma{abstractqlibra-is-sound}
%   Let $\definputvariables\in\variables$ be the input variable of interest, $\abstractdomain$ the abstract domain, $\backwardsemanticsnoparam$ the family of semantics, and $\buckets\in\vectorbuckets$ the starting output buckets.
%   Whenever the following conditions hold:
%   \begin{enumerate}[label=(\roman*)]
%     \item \label{rts1} $\buckets$ covers the subset of potential outcomes, \cf{} \refdef*{covering}[*-2],
%     \item \label{rts2} $\buckets$ is compatible with $\outputobs$, \cf{} \refdef*{compatibility}[*4],
%     \item \label{rts3} $\abstractdomainproject$ is sound, \cf{} \refdef*{soundness-project}[*8], and
%     \item \label{rts4} $\abstractdomainvolume$ is sound, \cf{} \refdef{soundness-volume}[*12];
%   \end{enumerate}
%   then, $\abstractqlibra$ is a sound implementation of $\qlibra$.
% \end{lemma}
% \begin{proof}
%   \denis{todo}
% \end{proof}


% \begin{example}
%   The quantities computed by the abstract implementation $\abstractqlibra$ in \refexample{abstract-qlibra} are sound over-approximations of the concrete implementation $\qlibra$:
%   \begin{align*}
%     & \qlibraname_{\{\texttt{angle}\}}(\dependencysemanticsnoparam\semanticsof{\landingprogram}) = 3 \\
%     &\qquad\GE \abstractqlibraname_{\{\texttt{angle}\}}(\presfrombuckets, \buckets) = 1
%   \end{align*}
%   \begin{align*}
%     & \qlibraname_{\{\texttt{speed}\}}(\dependencysemanticsnoparam\semanticsof{\landingprogram}) = 2 \\
%     &\qquad\GE \abstractqlibraname_{\{\texttt{speed}\}}(\presfrombuckets, \buckets) = 1
%   \end{align*}
%   as expected by \refthm*{soundness}, where $\landingprogram$ is the program of the landing alarm system, \cf{} \refprog{landing-alarm-system}.
% \end{example}


In this section, we present $\abstractqlibra$ as a sound implementation of $\qlibra$, computing an over-approximation of the volume of input space that may contain bias. Conversely, $\abstractqlibra$ computes an under-approximation of the fair input space.
As introduced at the beginning of this chapter, this analysis is too na\"ive to be practical, it is still useful for building upon later in the next section.

Instead of introducing an abstract implementation as a definition, we describe $\abstractqlibra$ in the form of a pseudo-code algorithm: \reffig{abstract-qlibra}.
The algorithm takes as input the neural-network model $\defmodel$, a set of input variables of interest $\definputvariables$ (the sensitive features), the $\numberofbuckets$ output buckets $\buckets$, and an abstract domain $\abstractdomain$.
The output buckets $\buckets$ represent all the possible classification targets of the neural network.
In this way, both covering (\refdef{covering}) and compatibility (\refdef{compatibility}) conditions are satisfied as all the target classes are covered and for any two different target classes, there exist two different output buckets representing them.
The analysis proceeds backwardly from each output bucket $\bucket$ via the backward semantics $\backwardsemanticsnoparam$ in order to determine an over-approximation of the initial states $\prefrombucket$.

Finally, the algorithm projects the input variables $\definputvariables$ from the abstract states $\prefrombucket$ to account for any possible permutations of their input values.
Then, it computes the pairwise intersections among the projected abstract states to find the portion of input space leading to different output buckets only via variations of the input variables $\definputvariables$.
The complement of such a volume is an over-approximation of the biased input space, hence an under-approximation of the fair input space.
The quantity measured by $\abstractqlibra$, algorithm in \reffig{abstract-qlibra}, is always lower than the concrete $\qlibra$.

\begin{lemma}[$\abstractqlibra$ is a Sound Implementation of $\qlibra$]\lablemma{abstractqlibra-is-sound}
  Let $\definputvariables\in\variables$ be the input variable of interest, $\abstractdomain$ the abstract domain, $\backwardsemanticsnoparam$ the family of semantics, and $\buckets\in\vectorbuckets$ the starting output buckets.
  Whenever the following conditions hold:
  \begin{enumerate}[label=(\roman*)]
    \item \label{nioa1} $\buckets$ covers the subset of potential outcomes, \cf{} \refdef*{covering}[*-2],
    \item \label{nioa2} $\buckets$ is compatible with $\outputobs$, \cf{} \refdef*{compatibility}[*4],
    \item \label{nioa3} $\backwardsemanticsnoparam$ is an exact backward semantics, \cf{} \reflemma{exact-backward-semantics}, and
    \item \label{nioa4} $\abstractdomainproject$ is sound, \cf{} \refdef*{soundness-project}[*8];
  \end{enumerate}
  then, $\abstractqlibra$ is a sound implementation of $\qlibra$.
\end{lemma}
\begin{proof}
  \denis{todo}
\end{proof}



Although sound, the abstract implementation $\abstractqlibra$ does not work well in presence of imprecision from the abstract domain employed during the backward analysis.
In fact, the abstract implementation $\abstractqlibra$ applied directly to the backward analysis represents the so called \emph{na\"ive casual-fairness analysis}~\sidecite{Urban2020}.
Such analysis suffers from the choice of existing abstract domains, which are rather fast but too imprecise to handle non-linear constraints, such as those arising from the activation functions in neural networks.
Indeed, even using the polyhedra domain for the backward analysis, handling the \relu{} activation function would over-approximate what effectively is a conditional branch, leading to a loss of precision that is reflected for each node of the neural network.
On the other hand, one could use a disjunctive completion of the polyhedra domain~\sidecite{Cousot1979}, which would retain a separate polyhedron each condition.
However, this analysis would be extremely slow.

\section{Parallel Analysis for Efficient Validation of the \texorpdfstring{$\boundedqlibra$ Property}{k-Bounded Impact Property applied to qlibra}}[Parallel Analysis]

To overcome the limitation of $\abstractqlibra$ described above, we first reason at a concrete-semantics level, introducing two additional semantics, the \emph{partitioning} and \emph{parallel semantics}.
Intuitively, we show how partitioning the input space into \emph{fair} partitions still allows for property validation.
Then, we show how to abstract the partitioning semantics into the parallel semantics, which is a sound over-approximation of the partitioning semantics.
Finally, we show how to validate the $\defbound$-bounded impact property for the parallel semantics.
In the abstract, such validation can now compute different fair partitions in parallel, the total volume is the sum of the volumes of the individual partitions.
This section is based on the work presented in \sidetextcite{Urban2020} and \sidetextcite{Mazzucato2021}.

\subsection{Parallel Semantics}\labsec{parallel-semantics}

We observe that the dependency semantics of a program satisfying the $\boundedqlibra$ property induces a partition of the input space restricted to the input variables in $\inputvariableswithoutw$.
We call this input partition \emph{fair}.

\begin{definition}[Fair Input Partition]\labdef{fair-input-partition}
  An input partition $\definputpartitions$ of $\reducedstate$ is \emph{fair} if all value choices $\values$ for the variables of interest $\definputvariables$ are possible in all the partitions:
  \begin{math}
    \forall \definputpartition\in\definputpartitions,\defvalue\in\values.\spacer
    \exists \retrieveinput\defstate\in\definputpartition.\spacer
    \retrieveinput\defstate(\definputvariables) = \defvalue
  \end{math}
\end{definition}

Given a fair input partition $\definputpartitions$ of $\reducedstate$, we can verify whether a program $\defprogram$ has an impact of $\defbound$ for each element $\definputpartition\in\definputpartitions$, \emph{independently}, and aggregate the results.

\begin{lemma}
  \begin{math}
    \defprogram \satisfies \boundedqlibra \IfF
    \sum_{\definputpartition\in\definputpartitions} \qlibra(\tracesemantics) \ge \defbound
  \end{math}
\end{lemma}

We exploit the above insight to further abstract the output-abstraction semantics $\outputabstraction$ to the \emph{parallel semantics} $\parallelsemantics$.
Formally, the right adjoint\sidenote{The left adjoint is uniquely defined by the right one.} $\parallelabstraction$ for the parallel semantics is defined as:
%
\begin{definition}[Right Adjoint for the Parallel Semantics]\labdef{right-adjoint-for-the-parallel-abstraction-semantics}
\begin{align*}
  \parallelabstraction \IN& \outputtype \to \paralleltype \\
  \parallelabstraction(\defsetofsetofdependencies) \DefeQ& \setdef{
    \partition{\defsetofdependencies}{\definputpartition}
  }{
    \defsetofdependencies \in \defsetofsetofdependencies \LanD \definputpartition\in\definputpartitions
  }
\end{align*}
\end{definition}

The order of the parallel semantics $\parallelsubseteq$ is the pointwise ordering between sets of pairs of states restricted to the same input partition of $\definputpartitions$. Formally,
\begin{align*}
  \defsetofsetofdependencies \parallelsubseteq \defsetofsetofdependencies' \IfF
  \forall \defsetofdependencies\in\defsetofsetofdependencies, \defsetofdependencies'\in\defsetofsetofdependencies'.\spacer
  \defsetofdependencies \neq \emptyset \land \defsetofdependencies' \neq \emptyset \ImplieS
  \bigwedge_{\definputpartition\in\definputpartitions}\partition{\defsetofdependencies}{\definputpartition} \subseteq \partition{\defsetofdependencies'}{\definputpartition}
\end{align*}

Ensuring that all the non-empty set of dependencies in $\defsetofsetofdependencies$ are included in $\defsetofsetofdependencies'$ for each input partition $\definputpartition$.
We have the following result:


\begin{theorem}\labthm{output-parallel-galois-connection}
  The two adjoints $\tuple{\parallelabstraction}{\parallelconcretization}$ form a \emph{Galois connection}:
\begin{align*}
  \galoisbetweensemantics{output}{parallel}
\end{align*}
\end{theorem}
\begin{proof}
  \denis{todo}
\end{proof}


We can now derive the parallel semantics as an abstraction of the output-abstraction semantics.

\begin{definition}[Parallel Abstraction Semantics]\labdef{parallel-abstraction-semantics}
  The \emph{parallel-abstraction semantics} $\parallelsemanticsnoparam\in\paralleltype$ is defined as:
  \begin{align*}
    \parallelsemanticsnoparam\DefeQ&\parallelabstraction(\outputsemanticsnoparam) \\
    % \spacearound{=}&\parallelabstraction(\{\spacearound{\setdef{\inputoutputtuple{\deftrace}}{\deftrace \in \tracesemanticsnoparam}}\}) \\
    \spacearound{=}&
    \setdef{\spacearound{
      \setdef{
        \tuple{\retrieveinput{\deftrace}}{\outputobs(\retrieveoutput{\deftrace})}
      }{
        \deftrace \in \partition\tracesemanticsnoparam\definputpartition
      }
    }}{\definputpartition\in\definputpartitions}
  \end{align*}
\end{definition}

It remains to show soundness and completeness for the parallel semantics when applied to the $\boundedqlibra$ property.
\begin{theorem}
  \begin{math}
    \defprogram \satisfies \boundedqlibra \IfF
    \parallelsemantics \parallelsubseteq \parallelabstraction(\outputabstraction(\dependencyabstraction(\boundedqlibra)))
  \end{math}
\end{theorem}
\begin{proof}
  \denis{todo}
\end{proof}

\subsection{Parallel Implementation \texorpdfstring{$\abstractqlibra$}{QLibra}}[Parallel \texorpdfstring{$\abstractqlibra$}{QLibra}]

In this section, we build upon the parallel semantics to design an abstract implementation $\abstractqlibra$ that computes an over-approximation of the volume of input space that may be fair.
This static analysis automatically find a fair partition of the input space, then computes the volume of the fair input space.
The abstract implementation $\abstractqlibra$ is defined as the sum of the volumes of the fair partitions, presented in \reffig{abstract-qlibra-parallel}.



\subsection{Abstract Domains for Neural Network Analysis}

Different abstract domains can be used for the forward pre-analysis of neural networks.
The choice of the abstract domain depends on the trade-off between precision and scalability.
Here, we present four abstract domains: \boxes, \symbolic, \deeppoly, and \neurify. Additionally, a generic reduced product domain construction, called \reducedproduct, to combine any of these domains together.

\paragraph{Boxes}


The \boxes{} domain simply uses interval arithmetic \sidecite{Hickey2001} to compute concrete lower and upper bound estimations $l$ and $u$ for the value of each neuron \texttt{x} in the neural network.


\paragraph{Symbolic Constant Propagation}

The \symbolic{} domain combines \boxes{} with symbolic constant propagation \sidecite{Mine2006symbolic}: in addition to being bounded by concrete lower and upper bounds, the value of each neuron \texttt{x} is represented symbolically as a linear combination of the input neurons and the value of the non-fixed ReLUs in previous layers. Specifically, given \texttt{x} bounded by $l < 0$ and $u > 0$, $\relu(x)$ is represented by a fresh symbolic variable bounded by $0$ and $u$ (\cf{} \reffig{naive}). By retaining variable dependencies, symbolic representations yield a tighter over-approximation of the value of each neuron in the network.


\paragraph{DeepPoly}

The \deeppoly{} domain associates to each neuron $x$ of a neural network concrete lower and upper bounds $l$ and $u$ as well as symbolic bounds expressed as linear combinations of neurons in the preceding layer of the network.
%
The concrete bounds are computed by back-substitution of the symbolic bounds up to the input layer. Non-fixed ReLUs are over-approximated by partially retaining dependencies with preceding neurons using the tighter convex approximation between those shown in \reffig{deeppoly} (i.e., the approximation shown on the left when $u \leq -l$, and the approximation shown on the right otherwise).

\paragraph{Neurify}

The \neurify{} domain similarly maintains symbolic lower and upper bounds $low$ and $up$ for each neuron $x$ of neural network. Unlike \deeppoly, concrete lower and upper bounds are computed for \emph{each} symbolic bound: $l_{low}$ and $u_{low}$ for the symbolic lower bound, and $l_{up}$ and $u_{up}$ for the symbolic upper bound.
%
The over-approximation of non-fixed ReLUs is done \emph{independently} for each symbolic bound, i.e., for the $low$ bound if $l_{low} < 0 < u_{low}$, and for the $up$ bound if $l_{up} < 0 < u_{up}$.
%
\reffig{neurify} shows the approximation for $l = l_{low} = l_{up}$ and $u = u_{low} = u_{up}$. In general, the slope of the symbolic constraints will differ through successive approximation steps.

\paragraph{Reduced Product}

Finally, the \emph{Product Builder} provides a parametric interface for constructing the product of any of the above domains.
The reduction function consists in an exchange of concrete bounds between domains. In particular, this allows determining tighter lower and upper bound estimations for each neuron in the network and thus reducing the over-approximation error introduced by the ReLUs.
New abstract domains only need to implement the interface to share bounds information to enable their combination with other domains by the Product Builder.
