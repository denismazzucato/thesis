\chapter{Quantitative Fairness for Neural Networks}
\labch{quantitative-fairness}

In this chapter, we introduce the context of neural network formal analysis: we define the transition system generated by a neural network, and we present the forward and backward reachability state semantics targeting neural networks. We then introduce the \changesname{} impact definition, which specifically targets jagged input spaces as the ones usually found in the presence of neural networks.
Furthermore, we introduce the \qlibraname{} impact definition to quantify the amount of bias as a measure of fairness. We then present the abstract implementation of the \changesname{} and \qlibraname{} impact definitions.

\emph{Dans ce chapitre, nous introduisons le contexte de l'analyse formelle des réseaux de neurones : nous définissons le système de transition généré par un réseau de neurones et nous présentons les sémantiques de l'état de la portée avant et arrière ciblant les réseaux de neurones. Nous introduisons ensuite la définition de l'impact \changesname{}, qui cible spécifiquement les espaces d'entrée irréguliers tels que ceux généralement trouvés en présence de réseaux de neurones. De plus, nous introduisons la définition de l'impact \qlibraname{} pour quantifier la quantité de biais en tant que mesure de l'équité. Nous présentons ensuite l'implémentation abstraite des définitions d'impact \changesname{} et \qlibraname{}.}

% \input{src/chapters/extensional/sas21/overview}
% \input{src/chapters/extensional/sas21/changes}
% \input{src/chapters/extensional/sas21/qlibra}
% \input{src/chapters/extensional/sas21/evaluation-changes}
% \input{src/chapters/extensional/sas21/evaluation-qlibra}

\section{Neural Network Analysis}
\labsec{neural-network-analysis}

This section introduces feed forward neural networks formally and the transition system generated by executing the model. We then present the forward and backward reachability state semantics targeting neural networks.

\subsection{Neural Networks}

A \emph{feed forward deep neural network} is a directed acyclic graph where each node represents a neuron, and each edge represents a connection between neurons.
The nodes are arranged in layers, where the first layer is the input layer ($\inputlayer$), the last layer is the output layer ($\outputlayer$), and the layers in between are called hidden layers ($\hiddenlayers$).
Each layer $\hiddenlayer{i}$ is composed of a set of $\cardinalitynospaces{\hiddenlayer{i}}$ nodes, and is connected to the previous layer $\hiddenlayer{i-1}$ through a weight $\cardinalitynospaces{\hiddenlayer{i}}\times\cardinalitynospaces{\hiddenlayer{i-1}}$-matrix $\weightmatrix{i}$ and a bias $\cardinalitynospaces{\hiddenlayer{i}}$-vector $\biasvector{i}$.
The set of all nodes is denoted by $\networknodes$ and the set of nodes in layer $\hiddenlayer{i}$ is denoted by $\networknodesinlayer{i}$. The $j$-th node in layer $\hiddenlayer{i}$ is denoted by $\node$.
In this thesis we focus on feed forward neural networks used for classification tasks, where each node in the output layer represents a class, and the output of the network is the class yielding the highest value. In total, the network has $\cardinalitynospaces{\outputlayer}$ number of target classes.

An input value is a $\cardinalitynospaces{\inputlayer}$-dimensional vector $\networknodesinlayer{0}$; for simplicity, we assume that the input values are normalized to the interval $[0,1]$.
The value of each hidden and output node is computed by applying an activation function to the weighted sum of the values of the nodes in the previous layer and the bias. The activation function is usually a non-linear function, we consider the \relu{} activation function in this work, which is defined as $\relu(x) = \max(0,x)$. Thus, the value of node $\node$ in layer $\hiddenlayer{i}$ is computed as:
\begin{align*}
  \node = \relu\left(
    \sum_{k}^{\cardinalitynospaces{\hiddenlayer{i-1}}}\weight_{j, k}^{i} \node[i-1][k] + \bias_{j}^{i}
  \right)
\end{align*}
where $\weight_{j, k}^{i}$ is the weight connecting node $\node[i-1][k]$ in layer $\hiddenlayer{i-1}$ to node $\node$ in layer $\hiddenlayer{i}$, and $\bias_{j}^{i}$ is the bias of node $\node$ in layer $\hiddenlayer{i}$. Weights and biases are learned during the training phase of the network. In the following, we consider already trained networks.

Given an input vector $\networknodesinlayer{0}$, the output of the network is the value of the nodes in the output layer $\networknodesinlayer{\cardinalitynospaces{\hiddenlayers}}$. The classification is the index of the node with the highest value, \ie{} $\argmax_{j} \node[\lastlayerindex][j]$.

\subsection{Transition System for Neural Networks}

\subsection{Forward Reachability State Semantics for Neural Networks}

\subsection{Backward Reachability State Semantics for Neural Networks}

\section{The \changesname{} Impact Definition}[\changesname]
\labsec{changes-impact-definition}

We introduce the first of the two quantitative impact metrics of this chapter, the \changesname{} impact definition.
This impact definition is designed to count how many times the network outcome changes by modification in the value of the input variable $\definputvariable$.
Notably, we recall similarities with the previously defined $\outcomesname$ impact definition: in this case, we consider changes in the outcome \emph{with repetitions}, that is, if two different variations in $\definputvariable$ result in the same change in outcome, it counts as double change.
The higher the number of changes in the outcome, the greater the influence on the program outcome.
Therefore, this definition demonstrates its effectiveness when the same outcomes are reachable by multiple variations.
Intuitively, such situation arises in the presence of neural networks, where generally all the possible input variations lead to every possible outcome.
Hence, the impact definitions defined in the previous chapter would not be useful.
Instead, counting the repetitions is a potential solution to define a meaningful impact definition for neural networks.

More specifically, the \changesname{} impact definition considers only variations in the value of input configurations that do not belong to the same \emph{continuous region}, containing no gaps or interruptions.
To this end, we first define the function $\segments$, which takes as input the set of traces of the neural network and an output value, and partitions the set of traces into continuous subsets with respect to the input variable $\definputvariable$.


\begin{definition}[Segments of Contiguous Regions]\labdef{segments}
\end{definition}

\begin{definition}[\changesname]\labdef{changes}
  Given an input variable $\definputvariable\in\inputvariables$, and an output descriptor $\outputdesc$,
  the quantity $\changes\in\dots$ is defined as:
  \begin{align*}
    \changes(\defsetoftraces) &\DefeQ \dots
  \end{align*}
\end{definition}

\denis{Here the algorithm for the abstract implementation of changes.}



\section{Outcome Semantics}
\labsec{outcome-semantics}


\begin{definition}[Adjoints for the Outcome Semantics]
  \labdef{adjoints-outcome-semantics}
  \begin{align*}
    \outcomeabstraction \IN& \inputoutputtype \to \outcometype \\
    \outcomeabstraction(\defsetofsetofdependencies) \DefeQ& \setdef{
      \setdef{\inputoutputtuple{\defseq} \in\defsetofdependencies}{\retrieveoutput{\defseq} = \defstate}
    }{
      \defsetofdependencies\in\defsetofsetofdependencies \land
      \defstate \in \stateandbottom
    }\\
    \outcomeconcretization \IN& \outcometype \to \inputoutputtype \\
    \outcomeconcretization(\defsetofsetofdependencies) \DefeQ& \setdef{
      \dots
    }{
      \dots
    }
  \end{align*}
\end{definition}

\begin{theorem}\labthm{inputoutput-outcome-galois-connection}
  The input-output $\inputoutputsemanticsnoparam$ and outcome $\outcomesemanticsnoparam$ semantics form a \emph{Galois Connection}:
\begin{align*}
  \galoisbetweensemantics{inputoutput}{outcome}
\end{align*}
\end{theorem}

\begin{definition}[Outcome Semantics]\labdef{outcome-semantics}
  \begin{align*}
    \outcomesemanticsnoparam\DefeQ& \outcomeabstraction(\inputoutputsemanticsnoparam)
  \end{align*}
\end{definition}

\begin{theorem}\labthm{outcome-validation}
  \begin{align*}
    \inputoutputsemantics \subseteq \unused \IfF \outcomesemantics \subseteq \outcomeabstraction(\unused)
  \end{align*}
\end{theorem}


\section{Parallel Semantics}
\labsec{parallel-semantics}


\begin{definition}[Adjoints for the Parallel Semantics]
  \labdef{adjoints-parallel-semantics}
  \begin{align*}
    \parallelabstraction \IN& \outcometype \to \paralleltype \\
    \parallelabstraction(\defsetofsetofdependencies) \DefeQ& \setdef{
      \dots
    }{
      \dots
    }\\
    \parallelconcretization \IN& \paralleltype \to \outcometype \\
    \parallelconcretization(\defsetofsetofdependencies) \DefeQ& \setdef{
      \dots
    }{
      \dots
    }
  \end{align*}
\end{definition}

\begin{theorem}\labthm{outcome-parallel-galois-connection}
  The input-output $\outcomesemanticsnoparam$ and parallel $\parallelsemanticsnoparam$ semantics form a \emph{Galois Connection}:
\begin{align*}
  \galoisbetweensemantics{outcome}{parallel}
\end{align*}
\end{theorem}

\begin{definition}[Parallel Semantics]\labdef{parallel-semantics}
  \begin{align*}
    \parallelsemanticsnoparam\DefeQ& \parallelabstraction(\outcomesemanticsnoparam)
  \end{align*}
\end{definition}

\begin{theorem}\labthm{parallel-validation}
  \begin{align*}
    \outcomesemantics \subseteq \unused \IfF \parallelsemantics \subseteq \parallelabstraction(\unused)
  \end{align*}
\end{theorem}



\section{The \qlibraname{} Impact Definition}[\qlibraname]
\labsec{qlibra-impact-definition}

\begin{definition}[\qlibraname]\labdef{qlibra}
  Given an input variable $\definputvariable\in\inputvariables$, and an output descriptor $\outputdesc$,
  the quantity $\qlibra\in\dots$ is defined as:
  \begin{align*}
    \qlibra(\defsetoftraces) &\DefeQ \dots
  \end{align*}
\end{definition}

\section{Abstract Implementation \texorpdfstring{$\abstractqlibra$}{Abstract QLibra}}[Abstract \texorpdfstring{$\abstractqlibra$}{QLibra}]
\labsec{abstract-qlibra}


\denis{Here the algorithm for the abstract implementation of changes.}

\section{Abstract Domains for Neural Network Verification}
\labsec{abstract-domains-for-neural-network-verification}

\subsection{Boxes}
\labsec{boxes}

\subsection{Symbolic Constant Propagation}
\labsec{symbolic-constant-propagation}

\subsection{DeepPoly}
\labsec{deeppoly}

\subsection{Neurify}
\labsec{neurify}


\section{Reduced Product}
\labsec{reduced-product}
