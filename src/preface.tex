%----------------------------------------------------------------------------------------
%	PREFACE
%----------------------------------------------------------------------------------------


\chapter*{Résumé}{\em
% \addcontentsline{toc}{chapter}{Abstract} % Add the preface to the table of contents as a chapter

The work presented in this thesis contributes to the development of mathematically rigorous and computationally efficient methods aimed at enhancing the reliability of software systems, particularly in domains where correctness and security are critical. The methods explored in this research are rooted in **abstract interpretation**, a well-established framework that systematically approximates program behaviors. This approach is especially valuable in environments where software failures can have catastrophic consequences, such as in medical devices, automotive control systems, and cryptographic applications. The primary goal is to design a **quantitative framework** that allows for the precise measurement of the influence that input variables have on software systems. This framework facilitates the verification of both desired behaviors and the identification of potential vulnerabilities, thus improving software correctness, performance, and security.

Software has become increasingly complex, and with that complexity comes the risk of subtle bugs that can evade detection through traditional testing methods. Although software testing remains a widely used technique, its limitations become particularly evident in safety-critical systems where the stakes are high. Testing can never exhaustively cover all possible inputs and behaviors, and the assurance it provides is necessarily incomplete. The traditional approach to testing, which involves feeding a finite set of inputs into the program and checking the outputs against expected results, often falls short, especially when dealing with the massive input spaces of modern software systems. Moreover, as the complexity of the software grows, the time and effort required for comprehensive testing increase exponentially, making it impractical for large-scale or highly critical systems.

This thesis proposes a different approach to software verification by employing **formal methods**. Formal methods use mathematical models to verify the behavior of software systems rigorously, providing stronger guarantees about correctness than testing can offer. In particular, this work builds on the theory of abstract interpretation, originally developed by Cousot and Cousot in the late 1970s. Abstract interpretation allows the computation of approximations of a program’s behavior that are sound -- that is, they conservatively estimate the program’s behavior so that any errors detected by the analysis are guaranteed to be real. By working with these sound approximations, it is possible to provide mathematical guarantees about the program's behavior, which is especially valuable in systems where correctness and security are paramount.

The central contribution of this thesis is the development of a **quantitative framework** for software analysis based on abstract interpretation. Unlike traditional program properties, which are typically qualitative (either a program satisfies a property or it does not), the quantitative framework introduced here allows for the measurement of how much certain input variables influence the program’s behavior. This is particularly useful in contexts where the degree of influence is important -- for example, in determining whether certain inputs disproportionately affect the outcome of a neural network model, or in measuring the extent to which input variables impact the execution time of a cryptographic algorithm.

The **quantitative input usage framework** introduced in this thesis is designed to provide flexible and parameterized methods for measuring the influence of input variables. The flexibility of the framework lies in its ability to adapt to different types of quantitative analysis based on the specific needs of the software system being analyzed. For example, in safety-critical systems, it may be necessary to certify that the influence of certain inputs remains within strict bounds to ensure that the system behaves predictably under all conditions. In other cases, the framework can be used to detect inputs that have an unexpectedly large impact on program behavior, indicating potential bugs or vulnerabilities. The results of the analysis are sound in the sense that they are guaranteed to be conservative estimates of the actual influence of the input variables. This soundness is crucial for ensuring that the analysis provides reliable guarantees about the software’s behavior.

The quantitative framework developed in this thesis is applied to both **extensional** and **intensional** properties of software. Extensional properties are concerned with the input-output behavior of programs -- that is, how variations in input affect the final output. Intensional properties, on the other hand, are concerned with the internal workings of the program, such as the number of loop iterations or the amount of memory used during execution. By analyzing both extensional and intensional properties, the framework provides a comprehensive view of how input variables influence program behavior, both in terms of the final result and the intermediate steps taken to compute that result.

To demonstrate the practical applicability of this framework, the thesis describes the development of three software tools: **Libra**, **Impatto**, and **TimeSec**, each of which is designed for a specific type of quantitative analysis.

1. **Libra** is a tool that focuses on the fairness of neural networks. Neural networks are increasingly being used in high-stakes decision-making systems, such as in healthcare, criminal justice, and social welfare, where biases in the input data can lead to unfair or discriminatory outcomes. Libra quantifies the impact of different input features on the neural network’s behavior, providing a way to detect and correct potential biases in the model. For example, if certain input features (such as race or gender) have an outsized impact on the network’s predictions, Libra can identify this issue, allowing developers to adjust the model to ensure more equitable outcomes. The tool was extensively tested in various use cases, showing how it can be applied to ensure fairness in machine learning systems.

2. **Impatto** is a general-purpose tool designed for analyzing the reliability of traditional software systems. It uses the quantitative framework developed in this thesis to measure the impact of input variables on software reliability, identifying inputs that may cause unintended or undesirable behavior. Impatto was validated through a series of experiments on different types of software, demonstrating its ability to detect potential vulnerabilities and certify the correctness of program behavior. One of the key strengths of Impatto is its flexibility -- it can be adapted to different types of software systems and different types of input influences, making it a powerful tool for ensuring software reliability across a wide range of applications.

3. **TimeSec** is a tool specifically developed for detecting timing-based side-channel vulnerabilities in cryptographic libraries. Side-channel attacks exploit variations in the execution time of cryptographic algorithms to infer sensitive information, such as secret keys. These attacks pose a significant threat to the security of cryptographic systems, as they can bypass traditional security measures. TimeSec quantifies the impact of input variables on the number of loop iterations during program execution, providing a way to detect and prevent timing-based vulnerabilities. The tool was successfully applied to the **s2n-bignum** cryptographic library, where it identified critical input variables that could affect the system's security by exposing it to side-channel attacks. The results from this analysis provide stronger guarantees than traditional empirical testing, offering a robust method for certifying the security of cryptographic systems.

The contributions of this thesis extend beyond the development of these tools. The quantitative framework proposed here provides a new way of thinking about software analysis, one that moves beyond traditional yes/no answers to verification problems and instead provides a more nuanced understanding of how input variables influence program behavior. This is especially valuable in systems where the relationship between inputs and outputs is complex, such as in machine learning models or cryptographic algorithms.

The **experimental validation** of this framework is a key component of the thesis. Each of the tools developed as part of this work was tested on real-world software systems, including neural networks and cryptographic libraries, to demonstrate the practical effectiveness of the quantitative analysis. These experiments showed that the framework is not only theoretically sound but also computationally efficient, providing useful results in a timely manner. The success of these experiments underscores the value of the quantitative framework in improving the reliability, security, and fairness of modern software systems.

Looking to the future, there are several exciting avenues for further research building on the work presented in this thesis. One area of interest is the development of new **abstract domains** that can more accurately capture non-linear relationships between variables. This would improve the precision of the quantitative analysis, making it even more useful for analyzing complex systems. Additionally, extending the framework to handle **non-deterministic** and **non-terminating programs** would broaden its applicability, allowing it to be used in a wider range of software systems. Another promising direction is the application of the framework to other types of machine learning models, such as **support vector machines** or **decision trees**, to ensure that these systems are also reliable and fair.

In conclusion, this thesis makes a significant contribution to the field of software verification by introducing a new quantitative framework for analyzing the impact of input variables on program behavior. The tools developed as part of this work -- Libra, Impatto, and TimeSec -- demonstrate the practical applicability of the framework, providing valuable insights into the reliability, security, and fairness of modern software systems. The methods presented here are grounded in rigorous theoretical development, supported by extensive experimental validation, and offer a strong foundation for future research and development in the field of software verification. As software continues to play an increasingly important role in critical systems, the need for reliable, secure, and fair software will only grow, and the contributions of this thesis provide important tools for meeting that need.

}
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract} % Add the preface to the table of contents as a chapter


\index{Preface}


The aim of this thesis is to develop mathematically sound and practically efficient methods for improving the reliability of software systems.
Our approach is based on abstract interpretation, a formal framework to systematically design approximate program behaviors.
We focus on the development of a quantitative framework for measuring the impact of input variables on the program behavior.
Advances in the understanding of input data usage in software systems produce a more correct, performant, and secure software, particularly in safety-critical systems where these factors are non-negotiable.


To achieve this goal, we propose a novel quantitative input usage framework to discriminate between input variables based on their influence on the program behavior.
This framework is flexible, parametrized in the notion of impact to suit various needs, thereby providing a method for both certification of intended behaviors and identification of potential flaws.
By employing abstract interpretation, our results are guaranteed to be sound, meaning that the quantified bounds on the impact of input variables are always greater (or always lower depending on the underlying over- or under-approximation) than the actual impact.
The major challenge, however, is to ensure that the quantification is precise enough to be useful in practice, while still being computationally efficient.


The quantitative framework is applied to verify both extensional and intensional properties of software. Extensional properties are based on the input-output behavior of programs, while intensional properties concern how the computations are performed. Specifically, the extensional property measures how variations in input data influence program output, whereas the intensional property assesses the impact of input data on the number of iterations within the program's loops during execution.
We quantify the impact of input variables by analyzing input-output dependencies in the program under evaluation.

To demonstrate the practical applicability of this framework, we implemented it into three distinct tools: \libra, \impatto, and \timesec, each designed for a specific type of quantitative analysis. \libra{} focuses on fairness of neural networks, \impatto{} is tailored for general-purpose software reliability analysis, and \timesec{} specializes in assessing side-channel vulnerabilities. The effectiveness of these tools was validated through extensive experimental evaluations across diverse use cases, from the quantification of biased space in neural networks to the detection of timing-based side-channel attacks in cryptographic libraries.
\libra's application in neural network analysis has provided insights into how input features influence model behavior, contributing to the development of more reliable machine learning systems.
\timesec{} has been shown to effectively quantify the impact of input variables in the Amazon Web Services \bignum{} library, enabling the identification of critical variables that may affect system stability or security.

Overall, the quantitative framework proposed in this thesis advances the understanding of input data usage in software systems, providing theoretical framework based on abstract interpretation and practical tools for quantifying the impact of input data. The experimental results highlight the utility of our quantitative framework, demonstrating its potential.
